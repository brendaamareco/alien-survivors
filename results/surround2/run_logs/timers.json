{
    "name": "root",
    "gauges": {
        "Surround.Policy.Entropy.mean": {
            "value": 2.0814015865325928,
            "min": 2.0400474071502686,
            "max": 2.1837639808654785,
            "count": 103
        },
        "Surround.Policy.Entropy.sum": {
            "value": 24976.8203125,
            "min": 11683.6875,
            "max": 30224.115234375,
            "count": 103
        },
        "Surround.Environment.EpisodeLength.mean": {
            "value": 999.0,
            "min": 482.25,
            "max": 999.0,
            "count": 103
        },
        "Surround.Environment.EpisodeLength.sum": {
            "value": 11988.0,
            "min": 5490.0,
            "max": 14142.0,
            "count": 103
        },
        "Surround.Step.mean": {
            "value": 1079818.0,
            "min": 59166.0,
            "max": 1079818.0,
            "count": 103
        },
        "Surround.Step.sum": {
            "value": 1079818.0,
            "min": 59166.0,
            "max": 1079818.0,
            "count": 103
        },
        "Surround.Policy.ExtrinsicBaselineEstimate.mean": {
            "value": 36.176109313964844,
            "min": 6.238386154174805,
            "max": 86.92507934570312,
            "count": 103
        },
        "Surround.Policy.ExtrinsicBaselineEstimate.sum": {
            "value": 361.7610778808594,
            "min": 37.49530029296875,
            "max": 2260.052001953125,
            "count": 103
        },
        "Surround.Policy.ExtrinsicValueEstimate.mean": {
            "value": 32.62482452392578,
            "min": 15.679435729980469,
            "max": 94.82211303710938,
            "count": 103
        },
        "Surround.Policy.ExtrinsicValueEstimate.sum": {
            "value": 326.24822998046875,
            "min": 94.16248321533203,
            "max": 2465.375,
            "count": 103
        },
        "Surround.Environment.CumulativeReward.mean": {
            "value": 41.46019979715347,
            "min": -15.82378454208374,
            "max": 174.63373336791992,
            "count": 103
        },
        "Surround.Environment.CumulativeReward.sum": {
            "value": 414.60199797153473,
            "min": -158.2378454208374,
            "max": 2285.567829094827,
            "count": 103
        },
        "Surround.Policy.ExtrinsicReward.mean": {
            "value": 400.40944213867186,
            "min": -82.65852203369141,
            "max": 985.8404663085937,
            "count": 103
        },
        "Surround.Policy.ExtrinsicReward.sum": {
            "value": 4004.0944213867188,
            "min": -826.5852203369141,
            "max": 14389.719619750977,
            "count": 103
        },
        "Surround.Environment.GroupCumulativeReward.mean": {
            "value": 26.5,
            "min": -0.5,
            "max": 67.72727272727273,
            "count": 103
        },
        "Surround.Environment.GroupCumulativeReward.sum": {
            "value": 265.0,
            "min": -5.0,
            "max": 1518.5,
            "count": 103
        },
        "Surround.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 103
        },
        "Surround.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 103
        },
        "Surround.Losses.PolicyLoss.mean": {
            "value": 0.013740087266672741,
            "min": 0.0113435530802235,
            "max": 0.022482224352036912,
            "count": 42
        },
        "Surround.Losses.PolicyLoss.sum": {
            "value": 0.013740087266672741,
            "min": 0.0113435530802235,
            "max": 0.022482224352036912,
            "count": 42
        },
        "Surround.Losses.ValueLoss.mean": {
            "value": 126.03831112023556,
            "min": 36.36107664397269,
            "max": 337.85306243896486,
            "count": 42
        },
        "Surround.Losses.ValueLoss.sum": {
            "value": 126.03831112023556,
            "min": 36.36107664397269,
            "max": 337.85306243896486,
            "count": 42
        },
        "Surround.Losses.BaselineLoss.mean": {
            "value": 192.58981461958453,
            "min": 117.84705583976977,
            "max": 1427.5258049242425,
            "count": 42
        },
        "Surround.Losses.BaselineLoss.sum": {
            "value": 192.58981461958453,
            "min": 117.84705583976977,
            "max": 1427.5258049242425,
            "count": 42
        },
        "Surround.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 42
        },
        "Surround.Policy.LearningRate.sum": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 42
        },
        "Surround.Policy.Epsilon.mean": {
            "value": 0.2,
            "min": 0.2,
            "max": 0.20000000000000007,
            "count": 42
        },
        "Surround.Policy.Epsilon.sum": {
            "value": 0.2,
            "min": 0.2,
            "max": 0.20000000000000007,
            "count": 42
        },
        "Surround.Policy.Beta.mean": {
            "value": 0.005,
            "min": 0.005,
            "max": 0.005000000000000001,
            "count": 42
        },
        "Surround.Policy.Beta.sum": {
            "value": 0.005,
            "min": 0.005,
            "max": 0.005000000000000001,
            "count": 42
        },
        "Surround.Self-play.ELO.mean": {
            "value": 1200.284981946513,
            "min": 1200.0094902694077,
            "max": 1200.284981946513,
            "count": 39
        },
        "Surround.Self-play.ELO.sum": {
            "value": 7201.709891679077,
            "min": 7200.056941616446,
            "max": 21604.05233098801,
            "count": 39
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1697245922",
        "python_version": "3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]",
        "command_line_arguments": "D:\\BREND\\Documents\\Unity\\Projects\\Alien survivors (v2)\\alien-survivors\\venv\\Scripts\\mlagents-learn config/Surround.yaml --run-id=surround2 --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.1.0+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1697250696"
    },
    "total": 4774.4327668999995,
    "count": 1,
    "self": 0.005588299999544688,
    "children": {
        "run_training.setup": {
            "total": 0.09609569999999978,
            "count": 1,
            "self": 0.09609569999999978
        },
        "TrainerController.start_learning": {
            "total": 4774.3310829,
            "count": 1,
            "self": 2.617004599989741,
            "children": {
                "TrainerController._reset_env": {
                    "total": 8.543124599999846,
                    "count": 6,
                    "self": 8.543124599999846
                },
                "TrainerController.advance": {
                    "total": 4763.073376400011,
                    "count": 172102,
                    "self": 2.364357599910363,
                    "children": {
                        "env_step": {
                            "total": 1394.9567465000277,
                            "count": 172102,
                            "self": 1199.4017349001008,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 193.83435429996734,
                                    "count": 172102,
                                    "self": 6.390904699937579,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 187.44344960002977,
                                            "count": 171942,
                                            "self": 187.44344960002977
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.7206572999595746,
                                    "count": 172102,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 4743.784008400075,
                                            "count": 172102,
                                            "is_parallel": true,
                                            "self": 3674.4943234999664,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0016995999997053701,
                                                    "count": 6,
                                                    "is_parallel": true,
                                                    "self": 0.0008298999995091094,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0008697000001962607,
                                                            "count": 12,
                                                            "is_parallel": true,
                                                            "self": 0.0008697000001962607
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1069.2879853001093,
                                                    "count": 172102,
                                                    "is_parallel": true,
                                                    "self": 12.976485500063518,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 15.79401350003662,
                                                            "count": 172102,
                                                            "is_parallel": true,
                                                            "self": 15.79401350003662
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1002.2019568999414,
                                                            "count": 172102,
                                                            "is_parallel": true,
                                                            "self": 1002.2019568999414
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 38.31552940006792,
                                                            "count": 172102,
                                                            "is_parallel": true,
                                                            "self": 18.85291909995096,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 19.462610300116964,
                                                                    "count": 344204,
                                                                    "is_parallel": true,
                                                                    "self": 19.462610300116964
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 3365.7522723000725,
                            "count": 172102,
                            "self": 7.301040800078681,
                            "children": {
                                "process_trajectory": {
                                    "total": 852.171566199991,
                                    "count": 172102,
                                    "self": 851.9821529999911,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.18941319999998996,
                                            "count": 2,
                                            "self": 0.18941319999998996
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 2506.2796653000028,
                                    "count": 43,
                                    "self": 94.88528619999806,
                                    "children": {
                                        "TorchPOCAOptimizer.update": {
                                            "total": 2411.3943791000047,
                                            "count": 1417,
                                            "self": 2411.3943791000047
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 6.999998731771484e-07,
                    "count": 1,
                    "self": 6.999998731771484e-07
                },
                "TrainerController._save_models": {
                    "total": 0.09757660000013857,
                    "count": 1,
                    "self": 0.003034599999409693,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.09454200000072888,
                            "count": 1,
                            "self": 0.09454200000072888
                        }
                    }
                }
            }
        }
    }
}